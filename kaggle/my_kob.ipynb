{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processing the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\") # set style for seaborn plots\n",
    "import tensorflow as tf\n",
    "# Machine learning\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectKBest, chi2\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (BaggingClassifier, ExtraTreesClassifier, \n",
    "                              GradientBoostingClassifier, VotingClassifier, \n",
    "                              RandomForestClassifier, AdaBoostClassifier)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置索引\n",
    "df.set_index('shot_id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不同列数据类型转换\n",
    "df[\"period\"] = df[\"period\"].astype('object')\n",
    "\n",
    "vars_to_category = [\"combined_shot_type\", \"game_event_id\", \"game_id\", \"playoffs\", \n",
    "                    \"season\", \"shot_made_flag\", \"shot_type\", \"team_id\"]\n",
    "for col in vars_to_category:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "target = copy_df['shot_made_flag'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#移除无关列\n",
    "vars_to_remove = [\"team_id\", \"team_name\", \"game_id\", \"game_event_id\", \n",
    "                  \"lat\", \"lon\", \"shot_made_flag\"]\n",
    "\n",
    "for var in vars_to_remove:\n",
    "    copy_df = copy_df.drop(var, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"counts\": copy_df[\"action_type\"].value_counts().sort_values()[:25]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_action_types = copy_df[\"action_type\"].value_counts().sort_values().index.values[:20]#将出现次数count在前20个的列入稀少名单\n",
    "copy_df.loc[copy_df[\"action_type\"].isin(rare_action_types), \"action_type\"] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#年月进行分离\n",
    "copy_df[\"game_date\"] = pd.to_datetime(copy_df[\"game_date\"])\n",
    "copy_df[\"game_year\"] = copy_df[\"game_date\"].dt.year\n",
    "copy_df[\"game_month\"] = copy_df[\"game_date\"].dt.month\n",
    "copy_df = copy_df.drop(\"game_date\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#时间转换，只要小于5秒的那些因素，这些因素的效果更明显，布尔类型\n",
    "copy_df[\"seconds_from_period_end\"] = 60 * copy_df[\"minutes_remaining\"] + copy_df[\"seconds_remaining\"]\n",
    "copy_df[\"last_5_sec_in_period\"] = copy_df[\"seconds_from_period_end\"] < 5\n",
    "\n",
    "# We can drop the rest of time related fields\n",
    "copy_df = copy_df.drop(\"minutes_remaining\", axis=1)\n",
    "copy_df = copy_df.drop(\"seconds_remaining\", axis=1)\n",
    "copy_df = copy_df.drop(\"seconds_from_period_end\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数值转换成25个区间\n",
    "#copy_df[\"x_zones\"] = pd.cut(copy_df[\"loc_x\"], bins=25)\n",
    "#copy_df[\"y_zones\"] = pd.cut(copy_df[\"loc_y\"], bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vs的变为1，@的变为0\n",
    "copy_df[\"home_play\"] = copy_df[\"matchup\"].str.contains(\"vs\").astype(\"int\")\n",
    "copy_df = copy_df.drop(\"matchup\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热编码\n",
    "pd.get_dummies(copy_df[\"action_type\"]).add_prefix(\"{}#\".format(\"action_type\"))\n",
    "categorial_vars = [\n",
    "    'action_type', 'combined_shot_type', 'period', 'season', 'shot_type',\n",
    "    'shot_zone_area', 'shot_zone_basic', 'shot_zone_range', 'game_year',\n",
    "    'game_month', 'opponent']\n",
    "\n",
    "for var in categorial_vars:\n",
    "    dummies = pd.get_dummies(copy_df[var])\n",
    "    dummies = dummies.add_prefix(\"{}#\".format(var))\n",
    "    copy_df.drop(var, axis=1, inplace=True)\n",
    "    copy_df = copy_df.join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_submit为shot_made_flag的缺失列\n",
    "#X为所有非缺失行（除开shot_made_flag)\n",
    "#Y为所有shot_made_flag非缺失行\n",
    "missing = target.isnull()\n",
    "data_submit = copy_df[missing]\n",
    "X = copy_df[~missing]\n",
    "Y = target[~missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, Y.shape)\n",
    "print(copy_df.shape)\n",
    "print(data_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用随机森林分类器，来提取X与Y最相关的30个特征\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, Y)\n",
    "\n",
    "feature_imp = pd.DataFrame(model.feature_importances_, index=X.columns, columns=[\"importance\"])\n",
    "feat_imp_30 = feature_imp.sort_values(\"importance\", ascending=False).head(30).index#降序排列\n",
    "feat_imp_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = np.unique(feat_imp_30) #去除4个方法选取的特征之间互相重复的\n",
    "print(\"Final features set:\\n\")\n",
    "for f in features:\n",
    "    print(\"\\t-{}\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = copy_df.loc[:, features]   #把这些有用的特征列提取出来\n",
    "data_submit = data_submit.loc[:, features]  #空缺数据\n",
    "X = X.loc[:, features]              #没有空缺的\n",
    "\n",
    "print(\"Clean dataset shape: {}\".format(copy_df.shape))\n",
    "print(\"Subbmitable dataset shape: {}\".format(data_submit.shape))\n",
    "print(\"Train features shape: {}\".format(X.shape))\n",
    "print(\"Target label shape: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2666          #获得可重复的结果\n",
    "processors = -1       #计算机将使用其所有核心并行处理代码。\n",
    "num_folds = 3         #交叉验证时的分区数量\n",
    "scoring=\"neg_log_loss\"  #损失评分指标\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型3,随机森林：\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator = RandomForestClassifier(warm_start=True, random_state=seed),\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],   #森林中树的个数\n",
    "        'criterion': ['gini', 'entropy'], #采用Gini指标还是信息增益指标\n",
    "        'max_features': [18, 20],        #寻找最佳分割时需要考虑的特征数目\n",
    "        'max_depth': [8, 10],          #（决策）树的最大深度。\n",
    "        'bootstrap': [True]         #建立决策树时，是否使用有放回抽样。\n",
    "    }, \n",
    "    cv = kfold, \n",
    "    scoring = scoring, \n",
    "    n_jobs = processors)\n",
    "\n",
    "rf_grid.fit(X, Y)\n",
    "\n",
    "#寻找的最佳参数值\n",
    "print(rf_grid.best_score_)\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = rf_grid.predict_proba(data_submit) #结果的第一列为我们想要的值\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission.add_prefix('shot_made_flag')\n",
    "\n",
    "submission[\"shot_made_flag\"]= preds[:,1]\n",
    "\n",
    "submission.to_csv(\"submiss.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "905919ac9f676445cd2d83973d8f665f11332e1216bb5c9c4ce4c571dc7088cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
